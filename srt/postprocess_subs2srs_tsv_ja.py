#!/usr/bin/env python3
"""Post-process TSV file generated by SUBS2SRS"""

import re

from airium import Airium
from fugashi import fugashi
from jamdict import Jamdict

# ┌─────────────────────────────────────────────────────────────────────────────
# │ Setup
# └─────────────────────────────────────────────────────────────────────────────
TARGET_WORD_FILE = r'C:\Users\pete\ALL\Languages\JA\SUBS2SRS\Black Lagoon\target_words.txt'
ANKI_TSV = r'C:\Users\pete\ALL\Languages\JA\SUBS2SRS\Black Lagoon\Black_Lagoon.tsv'
OUTPUT_FILE = ANKI_TSV.replace('.tsv', '_tagged.tsv')
jam = Jamdict()
tagger = fugashi.Tagger()

# ┌─────────────────────────────────────────────────────────────────────────────
# │ Jamdict Lookup
# └─────────────────────────────────────────────────────────────────────────────
def build_jamdict_table(jam: Jamdict, word: str) -> str:
    """Build a nice HTML table for the specified string."""
    lookup_result = jam.lookup(word)
    jam_datas = []
    for entry in lookup_result.entries:
        kanji_forms = '<br>'.join([str(kf) for kf in entry.kanji_forms])
        kana_forms = '<br>'.join([str(kf).strip() for kf in entry.kana_forms])
        senses = [str(s) for s in entry.senses]
        senses = [re.sub(r'\(\((.*)\)\)', '', s).strip() for s in senses]
        jam_datas.append([kanji_forms, kana_forms, senses])

    # Generate/format HTML table
    a = Airium()
    with a.table():
        for jd in jam_datas:
            with a.tr():
                a.td(_t=jd[0])
                a.td(_t=jd[1])

                with a.td():
                    with a.ol():
                        [a.li(_t=_) for _ in jd[2]]

    table = str(a)
    table = re.sub(r'(\n\s+|\n)', '', table)  # Unindent/unwrap
    return table

# ┌─────────────────────────────────────────────────────────────────────────────
# │ Processing
# └─────────────────────────────────────────────────────────────────────────────
# Load up files
with open(TARGET_WORD_FILE, 'r', encoding='utf-8') as f:
    target_words = [line.strip() for line in f]

with open(ANKI_TSV, 'r', encoding='utf-8') as f:
    tsv = [line.strip().split('\t') for line in f]

# Span-tag target words and lookup in JMDICT
for line in tsv:
    for word in target_words:
        if word in line[3]:
            # Get dictionary definitions
            try:
                lemmas = [w.feature.lemma for w in tagger(word) if w.feature.lemma]
                golden_boy = lemmas[0] if lemmas else word
                jam_table = build_jamdict_table(jam, golden_boy)
            except IndexError:
                jam_table = 'no_jam'

            line[3] = line[3].replace(word, f'<span class="target">{word}</span>')
            # target_words.remove(word)
            if len(line) > 4:
                line[4] += [jam_table]
            else:
                line += [[jam_table]]
            line += [jam_table]
    if len(line) < 5:
        line += ['hacked']


# Reorder tsv fields for easier import into Anki
tsv = [[_[3], '<br>'.join(_[4]), _[2], '', _[0]] for _ in tsv]
tsv = ['\t'.join(_) for _ in tsv]

with open(OUTPUT_FILE, 'w+', newline='\n', encoding='utf-8') as f:
    f.write('\n'.join(tsv))
